# app.py
import streamlit as st
import os
import time
import uuid
from rag_logic import initialize_rag_chain
from langchain_openai import ChatOpenAI


# ===== 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” =====
def init_session_state():
    defaults = {
        "messages": [],
        "rag_chain": None,
        "retriever": None,
        "api_key": None,
        "file_hash": None,
        "file_names": [],
        "chat_id": str(uuid.uuid4()),
        "question_count": 0,
        "processing": False,
        "selected_question": None,
        "last_clicked_question": None
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


# ===== 2. ë©”ì¸ =====
def main():
    init_session_state()
    st.set_page_config(
        page_title="ğŸ›ï¸ ê³¡ì„±êµ° AI ë¯¼ì›ìƒë‹´ë´‡",
        page_icon="ğŸ›ï¸",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # ë‹¤í¬ ëª¨ë“œ + ëª¨ë°”ì¼ ìŠ¤íƒ€ì¼
    st.markdown("""
    <style>
        :root { color-scheme: dark; }
        body, .stApp { background-color: #121212; color: #fff; }
        .main-header {
            background: linear-gradient(90deg, #222 0%, #444 100%);
            padding: 1.2rem; border-radius: 10px;
            text-align: center; margin-bottom: 1rem;
        }
        .main-header h2 { margin: 0; color: #fff; }
        .main-header p { margin: 0; font-size: 0.9em; color: #bbb; }
        .metric-card {
            background: #1e1e1e; color: #eee;
            padding: 1rem; border-radius: 8px;
            border-left: 4px solid #667eea; margin-bottom: 1rem;
            font-size: 0.95em;
        }
        .footer {
            padding: 0.8rem; text-align: center;
            font-size: 0.8em; color: #aaa; border-top: 1px solid #333;
            margin-top: 1.5rem;
        }
        @media (max-width: 768px) {
            .main-header h2 { font-size: 1.2em; }
            .main-header p { font-size: 0.8em; }
            .metric-card { font-size: 0.85em; padding: 0.8rem; }
            .footer { font-size: 0.7em; padding: 0.5rem; }
        }
    </style>
    """, unsafe_allow_html=True)

    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h2>ğŸ›ï¸ ê³¡ì„±êµ° AI ë¯¼ì›ìƒë‹´ë´‡</h2>
        <p>ê³¡ì„±êµ° ë¯¼ì›í¸ëŒ ê¸°ë°˜ AI ìƒë‹´ ì„œë¹„ìŠ¤</p>
    </div>
    """, unsafe_allow_html=True)

    setup_sidebar()

    if not st.session_state.api_key:
        st.warning("ğŸ”‘ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    initialize_system()
    display_chat_interface()
    display_footer()


# ===== 3. ì‚¬ì´ë“œë°” =====
def setup_sidebar():
    st.sidebar.title("API ì„¤ì •")
    key = st.sidebar.text_input("OpenAI API í‚¤", type="password", key="api_key_input")
    if key:
        st.session_state.api_key = key

    st.sidebar.markdown("---")
    st.sidebar.subheader("ë¹ ë¥¸ ì§ˆë¬¸")
    quick_qs = [
        "ì—¬ê¶Œì„ ë°œê¸‰ ë°›ê³  ì‹¶ì–´ìš”",
        "ì£¼ë¯¼ë“±ë¡ë“±ë³¸ì„ ë°œê¸‰ ë°›ê³  ì‹¶ì–´ìš”",
        "ì¸ê°ì¦ëª…ì„œë¥¼ ë°œê¸‰ ë°›ê³  ì‹¶ì–´ìš”",
        "ì •ë³´ê³µê°œë¥¼ ì²­êµ¬í•˜ê³  ì‹¶ì–´ìš”",
        "ê±´ì¶•í—ˆê°€ ì‹ ì²­ì„ í•˜ê³  ì‹¶ì–´ìš”"
    ]
    for q in quick_qs:
        if st.sidebar.button(q, key=f"btn_{q}"):
            if not st.session_state.processing and st.session_state.last_clicked_question != q:
                st.session_state.selected_question = q
                st.session_state.last_clicked_question = q

    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        init_session_state()
        st.experimental_rerun()


# ===== 4. ì‹œìŠ¤í…œ ì´ˆê¸°í™” =====
def initialize_system():
    pdf_path = "minweonpyeonram-2025.pdf"
    if not os.path.exists(pdf_path):
        st.error("âŒ 'minweonpyeonram-2025.pdf' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    file_hash = str(hash(open(pdf_path, "rb").read()))
    if not st.session_state.rag_chain or st.session_state.file_hash != file_hash:
        with st.spinner("ğŸ“„ ê³¡ì„±êµ° ë¯¼ì›í¸ëŒ(2025) ë¬¸ì„œ ë¶„ì„ ì¤‘..."):
            rag_chain, retriever, _ = initialize_rag_chain(
                st.session_state.api_key, [pdf_path], ["ê³¡ì„±êµ° ë¯¼ì›í¸ëŒ 2025"]
            )
            st.session_state.rag_chain = rag_chain
            st.session_state.retriever = retriever
            st.session_state.file_hash = file_hash
            st.session_state.file_names = ["ê³¡ì„±êµ° ë¯¼ì›í¸ëŒ 2025"]


# ===== 5. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ =====
def display_chat_interface():
    st.markdown(
        f"<div class='metric-card'>ğŸ“„ ë¬¸ì„œ: <b>{', '.join(st.session_state.file_names)}</b> | ğŸ’¬ ì§ˆë¬¸ ìˆ˜: {st.session_state.question_count}</div>",
        unsafe_allow_html=True
    )

    with st.expander("ì‚¬ìš© ì•ˆë‚´", expanded=False):
        st.markdown("""
        â€¢ ì‚¬ì´ë“œë°”ì—ì„œ ë¹ ë¥¸ ì§ˆë¬¸ í´ë¦­  
        â€¢ í•˜ë‹¨ ì±„íŒ…ì°½ì— ì§ì ‘ ì…ë ¥  
        â€¢ ì˜ˆì‹œ: "ì—¬ê¶Œì„ ë°œê¸‰ ë°›ê³  ì‹¶ì–´ìš”", "ë¶€ë™ì‚° ê±°ë˜ ì‹œ ì‹ ê³ ë°©ë²•ì„ ì•Œê³  ì‹¶ì–´ìš”"
        """)

    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    if st.session_state.selected_question and not st.session_state.processing:
        q = st.session_state.selected_question
        st.session_state.selected_question = None
        process_question_typing(q)

    if not st.session_state.processing:
        if prompt := st.chat_input("âœï¸ ë¯¼ì›ì—…ë¬´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            process_question_typing(prompt)


# ===== 6. íƒ€ìê¸° ìŠ¤íƒ€ì¼ ìˆœì°¨ ì¶œë ¥ =====
def process_question_typing(prompt, delay=0.02):
    """LLM ë‹µë³€ì„ í•œ ê¸€ìì”© ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥"""
    if st.session_state.processing:
        return
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user" \
       and st.session_state.messages[-1]["content"] == prompt:
        return

    st.session_state.processing = True
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.question_count += 1

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
                start_time = time.time()

                # ë¬¸ì„œ ê²€ìƒ‰
                docs = st.session_state.retriever.get_relevant_documents(prompt)
                context = "\n\n".join(
                    [f"[ì¶œì²˜: {d.metadata.get('source_info','?')}] {d.page_content}" for d in docs]
                )

                # LLM ì¤€ë¹„ (ìŠ¤íŠ¸ë¦¬ë°)
                llm = ChatOpenAI(
                    model="gpt-4o-mini",
                    temperature=0,
                    openai_api_key=st.session_state.api_key,
                    max_tokens=800,
                    streaming=True
                )

                prompt_text = f"""
ë‹¹ì‹ ì€ ê³¡ì„±êµ°ì˜ ë¯¼ì› ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê³¡ì„±êµ° ë¯¼ì›í¸ëŒì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ê·¸ë¦¬ê³  ìì„¸íˆ ë‹µë³€í•˜ì„¸ìš”.
ê´€ë ¨ëœ ë³„ì§€ ì„œì‹ë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”. 

ë¬¸ë§¥:
{context}

ì§ˆë¬¸:
{prompt}

ë‹µë³€:
"""

                container = st.empty()
                full_text = ""
                for chunk in llm.stream(prompt_text):
                    token = chunk.content if hasattr(chunk, "content") else str(chunk)
                    full_text += token
                    container.markdown(full_text)
                    time.sleep(delay)  # íƒ€ì ì†ë„ ì¡°ì ˆ

                elapsed = round(time.time() - start_time, 2)
                full_text += f"\n\n_â± {elapsed}ì´ˆ_"
                container.markdown(full_text)
                st.session_state.messages.append({"role": "assistant", "content": full_text})

        except Exception as e:
            err = f"âŒ ì˜¤ë¥˜: {e}"
            st.error(err)
            st.session_state.messages.append({"role": "assistant", "content": err})

    st.session_state.processing = False


# ===== 7. í‘¸í„° =====
def display_footer():
    st.markdown("""
    <div class="footer">
        ğŸ› ê³¡ì„±êµ°ì²­ | ğŸ“ 061-360-0000 | ğŸŒ www.gokseong.go.kr | ğŸ“ ì „ë‚¨ ê³¡ì„±êµ° ê³¡ì„±ì êµ°ì²­ë¡œ 15  
        âš  ë³¸ ì„œë¹„ìŠ¤ëŠ” AI ì•ˆë‚´ ì„œë¹„ìŠ¤ì´ë©°, ì •í™•í•œ ë¯¼ì›ì€ ë‹´ë‹¹ë¶€ì„œì— ë¬¸ì˜í•˜ì„¸ìš”.
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()



