# app.py
import streamlit as st
import os
import time
import re
from rag_logic import (
    prepare_vectorstore,
    build_retriever,
    build_streaming_llm,
    make_context_and_sources,
    build_final_prompt
)

# ---------------------------
# CSS í…Œë§ˆ (Buybrand ìŠ¤íƒ€ì¼ í†¤ ì•¤ ë§¤ë„ˆ + ë‹µë³€ ê°€ë…ì„± ê°•í™”)
# ---------------------------
THEME_CSS = """
<style>
:root {
  --brand-bg: #0b0b0c;
  --card-bg: #111214;
  --muted: #8B8D93;
  --text: #F5F6F8;
  --accent: #A6E3A1;
  --accent-2: #89B4FA;
  --border: #23252A;
}
.stApp {
  background: var(--brand-bg);
  color: var(--text);
  font-family: "Noto Sans KR", sans-serif;
}
.msg-bot p {
  line-height: 1.6;
  margin-bottom: 0.6rem;
}
.msg-bot strong {
  color: var(--accent);
}
.msg-indent {
  margin-left: 1.2em;
}
.step-num {
  color: var(--accent-2);
  font-weight: bold;
}
</style>
"""

# ---------------------------
def init_session_state():
    defaults = {
        "messages": [],
        "api_key": None,
        "question_count": 0,
        "processing": False,
        "selected_question": None,
        "last_clicked_question": None,
        "vector_dir": "faiss_minweonpyeonram_2025",
        "pdf_path": "minweonpyeonram-2025.pdf",
        "index_ready": False,
        "retriever": None,
        "file_names": ["ê³¡ì„±êµ° ë¯¼ì›í¸ëŒ 2025"],
        "typing_delay": 0.02
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

def render_hero():
    st.markdown(THEME_CSS, unsafe_allow_html=True)
    st.markdown("""
    <div class="hero">
      <div class="hero-eyebrow">ğŸ›ï¸ ê³¡ì„±êµ° AI ë¯¼ì›ìƒë‹´ë´‡</div>
      <div class="hero-title">ë¯¼ì›, ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ë“œë¦½ë‹ˆë‹¤.</div>
      <div class="hero-desc">ëª©ë¡ê³¼ ì ˆì°¨ë¥¼ ì½ê¸° ì‰½ê²Œ ë“¤ì—¬ì“°ê¸° + ìƒ‰ìƒ ê°•ì¡° ì ìš©</div>
    </div>
    """, unsafe_allow_html=True)

def main():
    init_session_state()
    st.set_page_config(page_title="ê³¡ì„±êµ° AI ë¯¼ì›ìƒë‹´ë´‡", page_icon="ğŸ›ï¸", layout="wide")

    render_hero()
    setup_sidebar()

    if not st.session_state.api_key:
        st.warning("ğŸ”‘ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    initialize_system()
    display_chat_interface()
    display_footer()

def setup_sidebar():
    st.sidebar.title("API ì„¤ì •")
    key = st.sidebar.text_input("OpenAI API í‚¤", type="password", key="api_key_input")
    if key: st.session_state.api_key = key

    st.sidebar.markdown("---")
    st.sidebar.subheader("ë¹ ë¥¸ ì§ˆë¬¸")
    for q in ["ì—¬ê¶Œì„ ë°œê¸‰ ë°›ê³  ì‹¶ì–´ìš”","ì „ì…ì‹ ê³  ë°©ë²•ì„ ì•Œê³  ì‹¶ì–´ìš”","ì¸ê°ì¦ëª…ì„œ ë°œê¸‰ ë°›ê³  ì‹¶ì–´ìš”","ì •ë³´ê³µê°œë¥¼ ì²­êµ¬ë°©ë²•ì„ ì•Œê³  ì‹¶ì–´ìš”","ê±´ì¶•í—ˆê°€ ì‹ ì²­ ì ˆì°¨ë¥¼ ì•Œê³  ì‹¶ì–´ìš”"]:
        if st.sidebar.button(q):
            if not st.session_state.processing and st.session_state.last_clicked_question != q:
                st.session_state.selected_question, st.session_state.last_clicked_question = q, q

    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        init_session_state()
        st.experimental_rerun()

def initialize_system():
    if not os.path.exists(st.session_state.pdf_path):
        st.error(f"âŒ '{st.session_state.pdf_path}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    if not st.session_state.index_ready:
        with st.spinner("ğŸ“„ ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘..."):
            vectorstore = prepare_vectorstore(
                st.session_state.api_key,
                [st.session_state.pdf_path],
                st.session_state.file_names,
                st.session_state.vector_dir
            )
            st.session_state.retriever = build_retriever(vectorstore, k=8)
            st.session_state.index_ready = True

def display_chat_interface():
    st.markdown(
        f"<div class='card'>ğŸ“„ ë¬¸ì„œ: <b>{', '.join(st.session_state.file_names)}</b> | ğŸ’¬ ì§ˆë¬¸ ìˆ˜: {st.session_state.question_count}</div>",
        unsafe_allow_html=True
    )
    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"], unsafe_allow_html=True)

    if st.session_state.selected_question and not st.session_state.processing:
        process_question_typing(st.session_state.selected_question)
        st.session_state.selected_question = None

    if not st.session_state.processing:
        if prompt := st.chat_input("âœï¸ ë¯¼ì›ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            process_question_typing(prompt)

def process_question_typing(prompt, delay=0.02):
    if st.session_state.processing: return
    if st.session_state.messages and st.session_state.messages[-1]["role"]=="user" and st.session_state.messages[-1]["content"]==prompt:
        return
    st.session_state.processing = True
    st.session_state.messages.append({"role":"user","content":prompt})
    st.session_state.question_count += 1

    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            container = st.empty()
            with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
                ctx, _, annex = make_context_and_sources(st.session_state.retriever, prompt)
                llm = build_streaming_llm("gpt-4o-mini", st.session_state.api_key, max_tokens=800, temperature=0)
                full_prompt = build_final_prompt(ctx, prompt, annex)

                full_text = ""
                for chunk in llm.stream(full_prompt):
                    token = getattr(chunk, "content", None)
                    if token:
                        full_text += token
                        container.markdown(full_text)
                        time.sleep(delay)

                # ğŸ“Œ 1) ë²ˆí˜¸ ì• ì¤„ë°”ê¿ˆ
                formatted_text = re.sub(r"\n*(\d+\.)", r"\n\n\1", full_text).strip()

                # ğŸ“Œ 2) ì£¼ìš” ì œëª© êµµê²Œ + ì»¬ëŸ¬
                keywords = ["ë¯¼ì›ì—…ë¬´ëª…", "ì²˜ë¦¬ê¸°ê°„", "êµ¬ë¹„ì„œë¥˜", "ìˆ˜ìˆ˜ë£Œ", "ì²˜ë¦¬ ì ˆì°¨"]
                for kw in keywords:
                    formatted_text = re.sub(fr"\n*({kw}\s*:)", rf"\n\n**<span style='color:#A6E3A1'>\1</span>**", formatted_text)

                # ğŸ“Œ 3) êµ¬ë¹„ì„œë¥˜ ëª©ë¡ ë¶ˆë¦¿ & ë“¤ì—¬ì“°ê¸°
                formatted_text = re.sub(r"(êµ¬ë¹„ì„œë¥˜\s*:\s*)(.+?)(?=(\n\n|$))",
                                        lambda m: m.group(1) + "\n" +
                                                  "\n".join([f"<span class='msg-indent'>â€¢ {item.strip()}</span>"
                                                              for item in m.group(2).split("\n") if item.strip()]),
                                        formatted_text, flags=re.S)

                # ğŸ“Œ 4) ì²˜ë¦¬ ì ˆì°¨ ë‹¨ê³„ (1ë‹¨ê³„:, 2ë‹¨ê³„:) ìƒ‰ìƒ ê°•ì¡° + ë“¤ì—¬ì“°ê¸°
                formatted_text = re.sub(r"(\d+\s*ë‹¨ê³„\s*:)",
                                        r"<span class='step-num'>\1</span>",
                                        formatted_text)

                st.session_state.messages.append({"role":"assistant",
                                                  "content":f"<div class='msg-bot'>{formatted_text}</div>"})

        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜: {e}")
            st.session_state.messages.append({"role":"assistant","content":str(e)})

    st.session_state.processing = False

def display_footer():
    st.markdown("""
    <div class="foot">
        ğŸ› ê³¡ì„±êµ°ì²­ | ğŸ“ 061-360-0000 | ğŸŒ www.gokseong.go.kr | ğŸ“ ì „ë‚¨ ê³¡ì„±êµ° ê³¡ì„±ì êµ°ì²­ë¡œ 15  
        âš  AI ì•ˆë‚´ ì„œë¹„ìŠ¤ì´ë©°, ì •í™•í•œ ë¯¼ì›ì€ ë‹´ë‹¹ë¶€ì„œì— ë¬¸ì˜í•˜ì„¸ìš”.
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()




